# -*- coding: utf-8 -*-
"""KaggleDataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hdr8GVVtfgenNThrRPTUCwGsEm0ahaJq
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import nltk
import spacy
import re
from sklearn.model_selection import train_test_split

# Load dataset
df = pd.read_csv("KaggleDataset_with_sarcasm.csv")  # contains text, sentiment, sarcasm

# Drop missing values
df.dropna(subset=["text", "sarcasm", "sentiment"], inplace=True)

# Normalize text
def preprocess_text(text):
    text = re.sub(r"http\S+|www.\S+", "", text)
    text = re.sub(r"[^A-Za-z\s]", "", text)
    text = text.lower()
    return text.strip()

df["clean_text"] = df["text"].apply(preprocess_text)

from sklearn.preprocessing import LabelEncoder

# Sentiment: strongly negative, negative, neutral, positive, strongly positive
sentiment_labels = ['very negative', 'negative', 'neutral', 'positive', 'very positive']
df = df[df['sentiment'].isin(sentiment_labels)]  # filter only the 5 sentiments

sentiment_encoder = LabelEncoder()
sarcasm_encoder = LabelEncoder()

df["sentiment_label"] = sentiment_encoder.fit_transform(df["sentiment"])
df["sarcasm_label"] = sarcasm_encoder.fit_transform(df["sarcasm"])  # sarcastic=1, non=0

from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize_data(texts, labels, max_len=128):
    encoding = tokenizer(
        list(texts),
        truncation=True,
        padding=True,
        max_length=max_len,
        return_tensors="pt"
    )
    return encoding, torch.tensor(labels)

import torch

# Sarcasm
X_sarcasm_train, X_sarcasm_test, y_sarcasm_train, y_sarcasm_test = train_test_split(
    df["clean_text"], df["sarcasm_label"], test_size=0.2, random_state=100, stratify=df["sarcasm_label"])

# Sentiment
X_sent_train, X_sent_test, y_sent_train, y_sent_test = train_test_split(
    df["clean_text"], df["sentiment_label"], test_size=0.2, random_state=100,stratify=df["sentiment_label"])

from transformers import BertForSequenceClassification
import torch # Import torch

# Import AdamW from torch.optim instead of transformers.optimization
from torch.optim import AdamW

# Sarcasm model
sarcasm_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
# Sentiment model
sentiment_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)

from torch.utils.data import DataLoader, TensorDataset
from transformers import get_scheduler
from tqdm import tqdm

def train_model(model, encoding, labels, epochs=20, batch_size=32, early_stopping_patience=3,):
    dataset = TensorDataset(encoding['input_ids'], encoding['attention_mask'], labels)
    dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)

    optimizer = AdamW(model.parameters(), lr=2e-5)
    lr_scheduler = get_scheduler("linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=epochs*len(dataloader))

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    model.train()
    for epoch in range(epochs):
        loop = tqdm(dataloader, leave=True)
        for batch in loop:
            b_input_ids, b_attention_mask, b_labels = [x.to(device) for x in batch]

            model.zero_grad()
            outputs = model(input_ids=b_input_ids, attention_mask=b_attention_mask, labels=b_labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
            lr_scheduler.step()

            loop.set_description(f"Epoch {epoch}")
            loop.set_postfix(loss=loss.item())

    return model

from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize_data(texts, labels, max_len=128):
    encoding = tokenizer(
        list(texts),
        truncation=True,
        padding=True,
        max_length=max_len,
        return_tensors="pt"
    )
    # Convert labels to a NumPy array before creating a tensor
    return encoding, torch.tensor(labels.to_numpy())

# Sarcasm
enc_sarcasm_train, lab_sarcasm_train = tokenize_data(X_sarcasm_train, y_sarcasm_train)
sarcasm_model = train_model(sarcasm_model, enc_sarcasm_train, lab_sarcasm_train)

# Sentiment
enc_sent_train, lab_sent_train = tokenize_data(X_sent_train, y_sent_train)
sentiment_model = train_model(sentiment_model, enc_sent_train, lab_sent_train)

from sklearn.metrics import classification_report

def evaluate_model(model, X_test, y_test):
    model.eval()
    encoding, labels = tokenize_data(X_test, y_test)
    input_ids, attention_mask = encoding['input_ids'], encoding['attention_mask']

    with torch.no_grad():
        outputs = model(input_ids.to(model.device), attention_mask=attention_mask.to(model.device))
        preds = torch.argmax(outputs.logits, axis=1)

    return classification_report(y_test, preds.cpu(), digits=4)

# Evaluate
print("Sarcasm Detection Report:")
print(evaluate_model(sarcasm_model, X_sarcasm_test, y_sarcasm_test))

print("Sentiment Detection Report:")
print(evaluate_model(sentiment_model, X_sent_test, y_sent_test))

def predict_sarcasm_and_sentiment(text, sarcasm_model, sentiment_model, tokenizer):
    import torch

    # Preprocess input text
    def preprocess(text):
        text = re.sub(r"http\S+|www.\S+", "", text)
        text = re.sub(r"[^A-Za-z\s]", "", text)
        return text.lower().strip()

    clean_text = preprocess(text)

    # Tokenize
    encoding = tokenizer(
        [clean_text],
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=128
    )
    input_ids = encoding['input_ids'].to(sarcasm_model.device)
    attention_mask = encoding['attention_mask'].to(sarcasm_model.device)

    # Predict Sarcasm
    sarcasm_model.eval()
    with torch.no_grad():
        output = sarcasm_model(input_ids=input_ids, attention_mask=attention_mask)
        sarcasm_pred = torch.argmax(output.logits, dim=1).item()

    # Predict Sentiment
    sentiment_model.eval()
    with torch.no_grad():
        output = sentiment_model(input_ids=input_ids, attention_mask=attention_mask)
        sentiment_pred = torch.argmax(output.logits, dim=1).item()

    # Decode predictions
    sarcasm_label = sarcasm_encoder.inverse_transform([sarcasm_pred])[0]
    sentiment_label = sentiment_encoder.inverse_transform([sentiment_pred])[0]

    return {
        "text": text,
        "sarcasm": sarcasm_label,
        "sentiment": sentiment_label
    }

user_input = input("Enter political news text: ")
result = predict_sarcasm_and_sentiment(user_input, sarcasm_model, sentiment_model, tokenizer)

print("\n Input:", result["text"])
print("Sarcasm Prediction:", result["sarcasm"])
print("Sentiment Prediction:", result["sentiment"])